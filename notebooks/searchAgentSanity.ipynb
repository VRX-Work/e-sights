{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_prompt() -> str:\n",
    "    return \"\"\"You are an advanced AI agent designed for forensic and compliance investigations, specializing in analyzing large email datasets. Your task is to investigate multiple accusations simultaneously, searching for evidence, extracting relevant information, and drawing conclusions. You have access to a SemanticHybridSearch tool that combines Elasticsearch for keyword-based lexical searches and Faiss for semantic searches.\n",
    "\n",
    "Key Responsibilities:\n",
    "- Generate and refine search queries for multiple accusations, providing both Elasticsearch queries and semantic search strings.\n",
    "- Analyze search results to extract relevant information.\n",
    "- Evaluate evidence to determine if it supports or refutes accusations.\n",
    "- Generate conclusions based on the accumulated evidence.\n",
    "\n",
    "Guidelines:\n",
    "- Maintain objectivity and avoid bias in your analysis.\n",
    "- Consider the context and relationships between different pieces of information.\n",
    "- Be thorough in your investigation, but also efficient in your search refinement.\n",
    "- Clearly distinguish between facts, inferences, and speculations in your reports.\n",
    "- Adapt your search and analysis strategies based on the unique aspects of each accusation.\n",
    "- Utilize both lexical (Elasticsearch) and semantic (Faiss) search capabilities effectively.\n",
    "\n",
    "You will be provided with specific instructions for each task. Always strive for accuracy, clarity, and relevance in your responses.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def initial_query_prompt() -> str:\n",
    "    return \"\"\"Task: Generate initial search queries for the following accusation, suitable for use with the SemanticHybridSearch tool.\n",
    "\n",
    "Accusation: {accusation_prompt}\n",
    "Response Format: Provide the response in JSON format with the following keys:\n",
    "elastic: Contains the Elasticsearch query in JSON format.\n",
    "semantic: Contains the semantic search query as a string.\n",
    "\n",
    "Guidelines:\n",
    "Unionized Search Approach:\n",
    "- Combine Elasticsearch and semantic search capabilities effectively. For example: Use Elasticsearch to filter specific fields (e.g., recipients, senders). Use semantic search to refine or specify the context within filtered results.\n",
    "- If only one type of search is required, leave the other key empty (e.g., {{}} for elastic or \"\" for semantic).\n",
    "\n",
    "Data Schema:\n",
    "{{\n",
    "  \"Subject\": \"Subject of mail\",\n",
    "  \"To\": \"All Recipients\",\n",
    "  \"From\": \"Name of sender\",\n",
    "  \"Cc\": \"All CC\",\n",
    "  \"Bcc\": \"All BCC\",\n",
    "  \"Date\": \"Date in datetime format\",\n",
    "  \"Attachment_Count\": \"Number of attachments\",\n",
    "  \"Mail_Body\": \"Content of the mail in plain text format\"\n",
    "}}\n",
    "\n",
    "Elasticsearch Query:\n",
    "- Focus on key terms and concepts relevant to the accusation.\n",
    "- Use appropriate Elasticsearch query DSL structures (e.g., bool, must, should, match, term).\n",
    "- Consider field-specific searches (e.g., subject, body, from, to) and apply boosts where necessary.\n",
    "- Ensure queries are broad enough to capture relevant information but specific enough to exclude irrelevant results.\n",
    "\n",
    "Semantic Search Query:\n",
    "- Use natural language to describe the context and meaning of the accusation.\n",
    "- Incorporate synonyms, related terms, and broader concepts to capture nuances beyond simple keywords.\n",
    "\n",
    "Efficiency and Contextual Relevance:\n",
    "- Adapt search strategies based on the unique aspects of each accusation.\n",
    "- Ensure objectivity and avoid bias in query generation.\n",
    "- Clearly distinguish between facts, inferences, and speculations.\n",
    "\n",
    "Output Example:\n",
    "{{\n",
    "  \"elastic\": {{\n",
    "    // Elasticsearch query here\n",
    "  }},\n",
    "  \"semantic\": \"Semantic search string here\"\n",
    "}}\n",
    "\n",
    "Do not provide a preamble or an explanation, the output should strictly be in JSON format with no comments\"\"\"  # Pass\n",
    "\n",
    "\n",
    "def refine_search_prompt() -> str:\n",
    "    return \"\"\"Task: Refine the search queries based on the current queries and extracted information to uncover more details about the accusation. Provide refined queries for both Elasticsearch and semantic search.\n",
    "\n",
    "Current Elasticsearch Query: {elastic_query}\n",
    "Current Semantic Query: {semantic_query}\n",
    "Extracted Info Summary: {info}\n",
    "Areas for Further Investigation: {areas}\n",
    "Accusation: {accusation_prompt}\n",
    "\n",
    "Guidelines:\n",
    "Unionized Search Approach:\n",
    "- Combine Elasticsearch and semantic search capabilities effectively. For example: Use Elasticsearch to filter specific fields (e.g., recipients, senders). Use semantic search to refine or specify the context within filtered results.\n",
    "- If only one type of search is required, leave the other key empty (e.g., {{}} for elastic or \"\" for semantic).\n",
    "\n",
    "Data Schema:\n",
    "{{\n",
    "  \"Subject\": \"Subject of mail\",\n",
    "  \"To\": \"All Recipients\",\n",
    "  \"From\": \"Name of sender\",\n",
    "  \"Cc\": \"All CC\",\n",
    "  \"Bcc\": \"All BCC\",\n",
    "  \"Date\": \"Date in datetime format\",\n",
    "  \"Attachment_Count\": \"Number of attachments\",\n",
    "  \"Mail_Body\": \"Content of the mail in plain text format\"\n",
    "}}\n",
    "\n",
    "Your refined queries should:\n",
    "- Build upon the insights gained from the extracted information.\n",
    "- Focus on areas where evidence is lacking or inconclusive.\n",
    "- Include any new relevant terms or concepts discovered in the previous search.\n",
    "- Be more specific than the initial queries, targeting the most promising areas for further investigation.\n",
    "- Utilize Elasticsearch-specific features for the lexical query and natural language for the semantic query.\n",
    "\n",
    "Refined Search Queries:\n",
    "\n",
    "{{\n",
    "  \"elastic\": {{\n",
    "    // Elasticsearch query here\n",
    "  }},\n",
    "  \"semantic\": \"Semantic search string here\"\n",
    "}}\n",
    "\n",
    "Do not provide a preamble or an explanation, the output should strictly be in JSON format with no comments\n",
    "\"\"\"  # Pass\n",
    "\n",
    "\n",
    "def information_extraction_prompt() -> str:\n",
    "    return \"\"\"Task: Extract relevant information from the hybrid search results related to the following accusation:\n",
    "\n",
    "Accusation: {accusation_prompt}\n",
    "\n",
    "Hybrid Search Results:\n",
    "{results}\n",
    "\n",
    "Analyze the results, which combine Elasticsearch and Faiss search outcomes. Each result contains fields like \"Subject\", \"To\", \"From\", \"Cc\", \"Bcc\", \"Date\", \"Attachment_Count\", and \"Mail_Body\".\n",
    "\n",
    "Provide the following information in JSON format:\n",
    "\n",
    "{{\n",
    "  \"accused_suspects\": [],\n",
    "  \"incident_details\": {{\n",
    "    \"events\": [\n",
    "      {{\n",
    "        \"details\": \"\",\n",
    "        \"description\": \"\",\n",
    "        \"date\": \"\",\n",
    "        \"uid\":\"\",\n",
    "      }}\n",
    "    ]\n",
    "  }},\n",
    "  \"other_parties\": {{\n",
    "    \"name\": {{\n",
    "      \"relationship\": \"\",\n",
    "      \"role\": \"\",\n",
    "      \"uid\":\"uid\",\n",
    "    }}\n",
    "  }},\n",
    "  \"summary\": \"\"\n",
    "}}\n",
    "\n",
    "Ensure all relevant information is included within this structure. Omit any explanations or additional text outside the JSON.\n",
    "\"\"\"  # Pass\n",
    "\n",
    "\n",
    "def analyze_evidence_prompt() -> str:\n",
    "    return \"\"\"Task: Analyze the extracted information and determine if it provides sufficient evidence for the accusation. If not, suggest areas for further investigation.\n",
    "\n",
    "Accusation: {accusation_prompt}\n",
    "\n",
    "Extracted Information:\n",
    "{info}\n",
    "\n",
    "Summary of Previous Information:\n",
    "{summary}\n",
    "\n",
    "Provide your analysis in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"credibility_and_reliability\": {{\n",
    "    \"events_analysis\": [\n",
    "      {{\n",
    "        \"event\": \"Description of the event\",\n",
    "        \"credibility_score\": \"Score from 0-100\",\n",
    "        \"reasoning\": \"Explanation for the credibility score\",\n",
    "        \"uid\": \"The uid of the source where event is mentioned\"\n",
    "      }}\n",
    "    ],\n",
    "    \"relationships_analysis\": [\n",
    "      {{\n",
    "        \"entity1\": \"Name of first entity\",\n",
    "        \"entity2\": \"Name of second entity\",\n",
    "        \"relationship\": \"Description of relationship\",\n",
    "        \"credibility_impact\": \"How this relationship affects credibility\",\n",
    "        \"uid\": \"The uid of the source where entities are mentioned\"\n",
    "      }}\n",
    "    ],\n",
    "    \"overall_credibility_assessment\": \"Summary of overall credibility\"\n",
    "  }},\n",
    "  \"sufficiency\": {{\n",
    "    \"conclusion\": \"One of: sufficient, partial, insufficient\",\n",
    "    \"confidence_score\": \"Score from 0-100\",\n",
    "    \"conclusion_statement\": \"Detailed explanation of the sufficiency conclusion\",\n",
    "    \"refrences\": [\"List of the uids referenced\"]\n",
    "  }},\n",
    "  \"areas_for_further_investigation\": [\n",
    "    \"List of specific areas or questions needing further investigation\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Ensure all relevant analysis is included within this structure. Omit any explanations or additional text outside the JSON.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "class State(TypedDict):\n",
    "    accusation: str\n",
    "    queries:Dict[Dict, str]\n",
    "    search_results: List[Dict]\n",
    "    extracted_info: Dict\n",
    "    analysis: Dict\n",
    "    search_count: int\n",
    "\n",
    "\n",
    "class SemanticHybridSearch:\n",
    "    def search(self, elastic_query: Dict, semantic_query: str) -> List[Dict]:\n",
    "        print(\"Queries:\", elastic_query, semantic_query)\n",
    "        return [{\"Possible Data\": \"Content\"}]\n",
    "\n",
    "class DummyLLM:\n",
    "    def invoke(self, code: str):\n",
    "        if code == \"init\":\n",
    "            return '{\"elastic\": {\"elatic_query\": \"init\"}, \"semantic\": \"Semantic Init\"}'\n",
    "\n",
    "        if code == \"info\":\n",
    "            return '{\"info\": \"Extracted Info\"}'\n",
    "        \n",
    "        if code == \"analyze\":\n",
    "            return '{\"sufficiency\": {\"conclusion\" : \"insufficient\"}, \"areas_for_further_investigation\": []}'\n",
    "\n",
    "\n",
    "class InvestigationAgent:\n",
    "    def __init__(self):\n",
    "        self.llm = DummyLLM()\n",
    "        self.search_tool = SemanticHybridSearch()\n",
    "        self.workflow = self._create_workflow()\n",
    "\n",
    "    def _create_workflow(self) -> StateGraph:\n",
    "        workflow = StateGraph(State)\n",
    "        workflow.add_node(\"initial_query\", self.initial_query_generation)\n",
    "        workflow.add_node(\"search\", self.perform_search)\n",
    "        workflow.add_node(\"extract_info\", self.information_extraction)\n",
    "        workflow.add_node(\"analyze\", self.evidence_analysis)\n",
    "        workflow.add_node(\"refine_query\", self.refine_query)\n",
    "\n",
    "        workflow.add_edge(\"initial_query\", \"search\")\n",
    "        workflow.add_edge(\"search\", \"extract_info\")\n",
    "        workflow.add_edge(\"extract_info\", \"analyze\")\n",
    "        workflow.add_conditional_edges(\"analyze\", self.should_continue_search, {\"end\": END, \"refine\": \"refine_query\"})\n",
    "        workflow.add_edge(\"refine_query\", \"search\")\n",
    "        workflow.set_entry_point(\"initial_query\")\n",
    "\n",
    "        return workflow.compile()\n",
    "\n",
    "    def initial_query_generation(self, state: State) -> Dict:\n",
    "        print(\"Started Execution: Initial Query Node\")\n",
    "        prompt = PromptTemplate.from_template(self._initial_query_prompt())\n",
    "        human_message = HumanMessage(content=prompt.format(accusation_prompt=state['accusation']))\n",
    "        ai_message = self.llm.invoke(\"init\")\n",
    "        queries = json.loads(ai_message)\n",
    "        return {\"queries\": queries}\n",
    "\n",
    "    def perform_search(self, state: Dict) -> Dict:\n",
    "        print(\"Started Execution: Performing Search\")\n",
    "        results = self.search_tool.search(state['queries']['elastic'], state['queries']['semantic'])\n",
    "        return {\"search_results\": results}\n",
    "\n",
    "    def information_extraction(self, state: State) -> Dict:\n",
    "        print(\"Started Execution: Extracting Info\")\n",
    "        prompt = PromptTemplate.from_template(self._information_extraction_prompt())\n",
    "        human_message = HumanMessage(content=prompt.format(\n",
    "            accusation_prompt=state['accusation'],\n",
    "            results=json.dumps(state['search_results'])\n",
    "        ))\n",
    "        ai_message = self.llm.invoke(\"info\")\n",
    "        extracted_info = json.loads(ai_message)\n",
    "        return {\"extracted_info\": extracted_info}\n",
    "\n",
    "    def evidence_analysis(self, state: State) -> Dict:\n",
    "        print(\"Started Execution: Analyzing Evidence\")\n",
    "        prompt = PromptTemplate.from_template(self._analyze_evidence_prompt())\n",
    "        human_message = HumanMessage(content=prompt.format(\n",
    "            accusation_prompt=state['accusation'],\n",
    "            info=json.dumps(state['extracted_info']),\n",
    "            summary=state.get('summary', 'None')\n",
    "        ))\n",
    "        ai_message = self.llm.invoke(\"analyze\")\n",
    "        analysis = json.loads(ai_message)\n",
    "        return {\"analysis\": analysis, \"search_count\": state[\"search_count\"] + 1}\n",
    "\n",
    "    def refine_query(self, state: State) -> Dict:\n",
    "        print(\"Started Execution: Refining Search\")\n",
    "        prompt = PromptTemplate.from_template(self._refine_search_prompt())\n",
    "        human_message = HumanMessage(content=prompt.format(\n",
    "            elastic_query=json.dumps(state['queries']['elastic']),\n",
    "            semantic_query=state['queries']['semantic'],\n",
    "            info=json.dumps(state['extracted_info']),\n",
    "            areas=json.dumps(state['analysis']['areas_for_further_investigation']),\n",
    "            accusation_prompt=state['accusation']\n",
    "        ))\n",
    "        ai_message = self.llm.invoke(\"init\")\n",
    "        refined_queries = json.loads(ai_message)\n",
    "        return {\"queries\": refined_queries}\n",
    "\n",
    "    def should_continue_search(self, state: State) -> str:\n",
    "        if state['search_count'] >= 3:\n",
    "            return \"end\"\n",
    "        if state['analysis']['sufficiency']['conclusion'] == \"sufficient\":\n",
    "            return \"end\"\n",
    "        # if state['search_count'] > 0 and not self._significant_difference(state['previous_analysis'], state['analysis']):\n",
    "        #     return \"end\"\n",
    "        return \"refine\"\n",
    "\n",
    "    def _significant_difference(self, prev_analysis: Dict, current_analysis: Dict) -> bool:\n",
    "        # Implement logic to compare previous and current analysis\n",
    "        # Return True if there's a significant difference, False otherwise\n",
    "        pass\n",
    "\n",
    "    def run_investigation(self, accusation: str) -> Dict:\n",
    "        inputs = {\n",
    "            \"accusation\": accusation,\n",
    "            \"search_count\": 0,\n",
    "            \"previous_analysis\": None\n",
    "        }\n",
    "        \n",
    "        for output in self.workflow.stream(inputs):\n",
    "            if \"search_count\" in output:\n",
    "                output[\"search_count\"] += 1\n",
    "            if \"analysis\" in output:\n",
    "                output[\"previous_analysis\"] = output[\"analysis\"]\n",
    "            print(f\"Output: {json.dumps(output, indent=2)}\")\n",
    "            print(\"---------------------------------------------\\n\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def _initial_query_prompt() -> str:\n",
    "        return initial_query_prompt()\n",
    "\n",
    "    @staticmethod\n",
    "    def _refine_search_prompt() -> str:\n",
    "        return refine_search_prompt()\n",
    "\n",
    "    @staticmethod\n",
    "    def _information_extraction_prompt() -> str:\n",
    "        return information_extraction_prompt()\n",
    "\n",
    "    @staticmethod\n",
    "    def _analyze_evidence_prompt() -> str:\n",
    "        return analyze_evidence_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = InvestigationAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Execution: Initial Query Node\n",
      "Output: {\n",
      "  \"initial_query\": {\n",
      "    \"queries\": {\n",
      "      \"elastic\": {\n",
      "        \"elatic_query\": \"init\"\n",
      "      },\n",
      "      \"semantic\": \"Semantic Init\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Performing Search\n",
      "Queries: {'elatic_query': 'init'} Semantic Init\n",
      "Output: {\n",
      "  \"search\": {\n",
      "    \"search_results\": [\n",
      "      {\n",
      "        \"Possible Data\": \"Content\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Extracting Info\n",
      "Output: {\n",
      "  \"extract_info\": {\n",
      "    \"extracted_info\": {\n",
      "      \"info\": \"Extracted Info\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Analyzing Evidence\n",
      "Output: {\n",
      "  \"analyze\": {\n",
      "    \"analysis\": {\n",
      "      \"sufficiency\": {\n",
      "        \"conclusion\": \"insufficient\"\n",
      "      },\n",
      "      \"areas_for_further_investigation\": []\n",
      "    },\n",
      "    \"search_count\": 1\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Refining Search\n",
      "Output: {\n",
      "  \"refine_query\": {\n",
      "    \"queries\": {\n",
      "      \"elastic\": {\n",
      "        \"elatic_query\": \"init\"\n",
      "      },\n",
      "      \"semantic\": \"Semantic Init\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Performing Search\n",
      "Queries: {'elatic_query': 'init'} Semantic Init\n",
      "Output: {\n",
      "  \"search\": {\n",
      "    \"search_results\": [\n",
      "      {\n",
      "        \"Possible Data\": \"Content\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Extracting Info\n",
      "Output: {\n",
      "  \"extract_info\": {\n",
      "    \"extracted_info\": {\n",
      "      \"info\": \"Extracted Info\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Analyzing Evidence\n",
      "Output: {\n",
      "  \"analyze\": {\n",
      "    \"analysis\": {\n",
      "      \"sufficiency\": {\n",
      "        \"conclusion\": \"insufficient\"\n",
      "      },\n",
      "      \"areas_for_further_investigation\": []\n",
      "    },\n",
      "    \"search_count\": 2\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Refining Search\n",
      "Output: {\n",
      "  \"refine_query\": {\n",
      "    \"queries\": {\n",
      "      \"elastic\": {\n",
      "        \"elatic_query\": \"init\"\n",
      "      },\n",
      "      \"semantic\": \"Semantic Init\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Performing Search\n",
      "Queries: {'elatic_query': 'init'} Semantic Init\n",
      "Output: {\n",
      "  \"search\": {\n",
      "    \"search_results\": [\n",
      "      {\n",
      "        \"Possible Data\": \"Content\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Extracting Info\n",
      "Output: {\n",
      "  \"extract_info\": {\n",
      "    \"extracted_info\": {\n",
      "      \"info\": \"Extracted Info\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n",
      "Started Execution: Analyzing Evidence\n",
      "Output: {\n",
      "  \"analyze\": {\n",
      "    \"analysis\": {\n",
      "      \"sufficiency\": {\n",
      "        \"conclusion\": \"insufficient\"\n",
      "      },\n",
      "      \"areas_for_further_investigation\": []\n",
      "    },\n",
      "    \"search_count\": 3\n",
      "  }\n",
      "}\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analyze': {'analysis': {'sufficiency': {'conclusion': 'insufficient'},\n",
       "   'areas_for_further_investigation': []},\n",
       "  'search_count': 3}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.run_investigation(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
